{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Guilherme dos Santos Martins\n",
    "\n",
    "Nome: Giovana Cassoni Andrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\r\n",
    "# !pip install emoji\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "import emoji\r\n",
    "from emoji import UNICODE_EMOJI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostrando o diretório"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "/Users/giovanaandrade/Documents/Insper/Ciência dos Dados/Projeto 1/Projeto1_C.Dados-3\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\r\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Air Fryer.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dados do Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Treinamento</th>\n      <th>Relevância</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>air fryer pra canhoto</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@vanessapeitos @daizenbvc o franky conseguiria...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>adoro poder aplicar meus conhecimentos de enge...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@leilodecornohu1 \"amigo estamos falando de buc...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>se eu n mandar isso aqui na dm de alguma esqui...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                         Treinamento  Relevância\n0                              air fryer pra canhoto           1\n1  @vanessapeitos @daizenbvc o franky conseguiria...           0\n2  adoro poder aplicar meus conhecimentos de enge...           1\n3  @leilodecornohu1 \"amigo estamos falando de buc...           0\n4  se eu n mandar isso aqui na dm de alguma esqui...           0"
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\r\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweets do treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0                                  air fryer pra canhoto\n1      @vanessapeitos @daizenbvc o franky conseguiria...\n2      adoro poder aplicar meus conhecimentos de enge...\n3      @leilodecornohu1 \"amigo estamos falando de buc...\n4      se eu n mandar isso aqui na dm de alguma esqui...\n                             ...                        \n295    @annaborgess air fryer eh foda simplesmente a ...\n296    e @chromavka que escolheria brócolis na air fr...\n297        estou morando em brasilia ou em uma air fryer\n298    queria agradecer ao ser humano que inventou a ...\n299    air fryer filha da puta, prega os trem tudo va...\nName: Treinamento, Length: 300, dtype: object"
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilidades iniciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(0.58, 0.42)"
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probN = train.Relevância.value_counts(True)[0]\r\n",
    "probR = train.Relevância.value_counts(True)[1]\r\n",
    "probR, probN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dados do Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Teste</th>\n      <th>Relevância</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@poetatulio @tatyene_mendes isso é uma xota ou...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>comprei uma air fryer p minha mãe, o bagulho caro</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>usando air fryer como se não houvesse o amanhã</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>minha mãe comprou uma air fryer e já ama mais ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>repita comigo: churrasco na air fryer não existe!</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                               Teste  Relevância\n0  @poetatulio @tatyene_mendes isso é uma xota ou...           0\n1  comprei uma air fryer p minha mãe, o bagulho caro           0\n2     usando air fryer como se não houvesse o amanhã           1\n3  minha mãe comprou uma air fryer e já ama mais ...           1\n4  repita comigo: churrasco na air fryer não existe!           0"
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\r\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\r\n",
    "## Classificador automático de sentimento\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu produto e o que considerou como relevante ou não relevante na classificação dos tweets.\n",
    "\n",
    "O produto analisado foi a Air Fryer, fritadeira que não utiliza de óleo e que é provém de diversas marcas e podendo ter preços variados.\n",
    "Nossa classificação sobre a relevância de um tweet foi se ele falava bem ou mal do nosso produto analisado, sendo bem o relevante e mal um irrelevante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando as funções de cleanup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \r\n",
    "\r\n",
    "def cleanup(text):\r\n",
    "    punctuation = '[@!-.:?;()]'\r\n",
    "    pattern = re.compile(punctuation)\r\n",
    "    text_subbed = re.sub(pattern, '', text)\r\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup2(text):\r\n",
    "    paragrafo = '\\n'\r\n",
    "    pattern = re.compile(paragrafo)\r\n",
    "    text_subbed = re.sub(pattern, ' ', text)\r\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup3(text):\r\n",
    "    punctuation = '\\/'\r\n",
    "    pattern = re.compile(punctuation)\r\n",
    "    text_subbed = re.sub(pattern, ' ', text)\r\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando os tweets pela classificação da relevância"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainR = train.loc[train['Relevância'] == 1,:]\r\n",
    "trainN = train.loc[train['Relevância'] == 0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformando os tweets relevantes em string e adicionando a uma lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainR = trainR.Treinamento.apply(str)\r\n",
    "trainR = trainR.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformando os tweets não relevantes em string e adicionando a uma lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainN = trainN.Treinamento.apply(str)\r\n",
    "trainN = trainN.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fazendo o cleanup em ambas as listas de tweets e o split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringR = \" \"\r\n",
    "for i in trainR:\r\n",
    "    stringR = stringR + i + ' '\r\n",
    "stringR = stringR.lower()\r\n",
    "stringR = stringR.replace('air fryer', 'PRODUTO ')\r\n",
    "stringR = cleanup3(cleanup2(cleanup(stringR)))\r\n",
    "palavrasR = stringR.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringN = \" \"\r\n",
    "for i in trainN:\r\n",
    "    stringN = stringN + i + ' '\r\n",
    "stringN = stringN.lower()\r\n",
    "stringN = stringN.replace('air fryer', 'PRODUTO ')\r\n",
    "stringN = cleanup3(cleanup2(cleanup(stringN)))\r\n",
    "palavrasN = stringN.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando duas Series, uma com todas as palavras dos tweets relevantes e outra com todas as palavras dos tweets não relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_tweets_relevantes = pd.Series(palavrasR)\n",
    "serie_tweets_nao_relevantes = pd.Series(palavrasN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contagem de cada uma das palavras de ambas as Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_tweets_relevantes = serie_tweets_relevantes.value_counts()\n",
    "tabela_tweets_nao_relevantes = serie_tweets_nao_relevantes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contagem dos valores relativos de ambas as Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_tweets_relevantes_relativa = serie_tweets_relevantes.value_counts(True)\n",
    "tabela_tweets_nao_relevantes_relativa = serie_tweets_nao_relevantes.value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformando a tabela original Treinamento em string e lista para ter todos os tweets, não importando a classificação de relevância"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_str = train.Treinamento.apply(str)\n",
    "train = train_str.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fazendo o cleanup e split de todos os tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \" \"\n",
    "for i in train:\n",
    "    string = string + i + ' '\n",
    "string = string.lower()\n",
    "string = string.replace('air fryer', 'PRODUTO ')\n",
    "string = cleanup3(cleanup2(cleanup(string)))\n",
    "palavras = string.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando a Series com todas as palavras de todos os tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_tweets = pd.Series(palavras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando uma grande lista de pequenas listas, onde cada uma das pequenas listas contém um tweet. Nessa lista estão todos os tweets analisados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_dos_tweets = []\n",
    "lista_tweet = []\n",
    "for tweet in train:\n",
    "  lista_tweet.append(tweet)\n",
    "  lista_dos_tweets.append(lista_tweet)\n",
    "  lista_tweet = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A etapa abaixo faz com que todas as palavras repetidas não sejam levadas em consideração, para não haver repetição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_nao_repetidas = []\n",
    "for i in palavras:\n",
    "    if i not in palavras_nao_repetidas:\n",
    "        palavras_nao_repetidas.append(i)\n",
    "tabela_nao_repetidas = pd.Series(palavras_nao_repetidas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percorrendo a lista de listas, fez a etapa do cleanup e do split em todos os tweets, criando uma grande lista de pequenas listas, nas quais possuem as palavras listadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "y = []\n",
    "while i < 300:\n",
    "   x = lista_dos_tweets[i]\n",
    "   x = x[0].lower()\n",
    "   x = x.replace('air fryer', 'PRODUTO ')\n",
    "   x = cleanup3(cleanup2(cleanup(x)))\n",
    "   x=x.split()\n",
    "   y.append(x)\n",
    "   i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em ambas as etapas abaixo, é realizado a suavização de Laplace, calculando a probabilidade de, levando em consideração os dados relevantes, ser uma frase relevante, e também calculando a probabilidade de, levando em consideração os dados não relevantes, ser uma frase não relevante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "listaR = []\n",
    "while i < 300:\n",
    "    p = y[i]\n",
    "    probFraseDadoR = 1\n",
    "    for n in p:\n",
    "        if n in tabela_tweets_relevantes:\n",
    "            probFraseDadoR = probFraseDadoR * ((tabela_tweets_relevantes[n]+1)/(len(tabela_tweets_relevantes)+len(tabela_nao_repetidas)))\n",
    "        else:\n",
    "            probFraseDadoR = probFraseDadoR * (1/(len(tabela_tweets_relevantes)+len(tabela_nao_repetidas)))\n",
    "    listaR.append(probFraseDadoR)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "listaN = []\n",
    "while i < 300:\n",
    "    p = y[i]\n",
    "    probFraseDadoN = 1\n",
    "    for n in p:\n",
    "        if n in tabela_tweets_nao_relevantes:\n",
    "            probFraseDadoN = probFraseDadoN * ((tabela_tweets_nao_relevantes[n]+1)/(len(tabela_tweets_nao_relevantes)+len(tabela_nao_repetidas)))\n",
    "        else:\n",
    "            probFraseDadoN = probFraseDadoN * (1/(len(tabela_tweets_nao_relevantes)+len(tabela_nao_repetidas)))\n",
    "    listaN.append(probFraseDadoN)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em ambas as etapas abaixo, calcula-se a probabilidade de, dado uma frase, ela ser relevante, e também calcula-se a probabilidade de, dado uma frase não relevante, ela ser não relevante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "listar = []\n",
    "while i < 300:\n",
    "    probRDadoFrase = listaR[i] * probR\n",
    "    listar.append(probRDadoFrase)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "listan = []\n",
    "while i < 300:\n",
    "    probNDadoFrase = listaN[i] * probN\n",
    "    listan.append(probNDadoFrase)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando uma lista com os níveis de relevância dos tweets do excel Treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "relevancia = []\n",
    "while i < 300:\n",
    "    if listar[i] > listan[i]:\n",
    "        relevancia.append(1)\n",
    "    else:\n",
    "        relevancia.append(0)\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando uma função com todos esses passos realizados acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relevante(lista_de_tweet):\n",
    "    lista_dos_tweets2 = []\n",
    "    lista_tweet2 = []\n",
    "    for tweet in lista_de_tweet:\n",
    "        lista_tweet2.append(tweet)\n",
    "        lista_dos_tweets2.append(lista_tweet2)\n",
    "        lista_tweet2 = []\n",
    "\n",
    "    i = 0\n",
    "    y1 = []\n",
    "    while i < 200:\n",
    "        x = lista_dos_tweets2[i]\n",
    "        x = x[0].lower()\n",
    "        x = x.replace('air fryer', 'PRODUTO ')\n",
    "        x = cleanup3(cleanup2(cleanup(x)))\n",
    "        x=x.split()\n",
    "        y1.append(x)\n",
    "        i += 1\n",
    "        \n",
    "    i = 0\n",
    "    listaR = []\n",
    "    while i < 200:        \n",
    "        p = y1[i]\n",
    "        probFraseDadoR = 1\n",
    "        for n in p:\n",
    "            if n in tabela_tweets_relevantes:\n",
    "                probFraseDadoR = probFraseDadoR * ((tabela_tweets_relevantes[n]+1)/(len(tabela_tweets_relevantes)+len(tabela_nao_repetidas)))\n",
    "            else:\n",
    "                probFraseDadoR = probFraseDadoR * (1/(len(tabela_tweets_relevantes)+len(tabela_nao_repetidas)))\n",
    "        listaR.append(probFraseDadoR)\n",
    "        i += 1\n",
    "\n",
    "    i = 0\n",
    "    listaN = []\n",
    "    while i < 200:       \n",
    "        p = y1[i]\n",
    "        probFraseDadoN = 1\n",
    "        for n in p:\n",
    "            if n in tabela_tweets_nao_relevantes:\n",
    "                probFraseDadoN = probFraseDadoN * ((tabela_tweets_nao_relevantes[n]+1)/(len(tabela_tweets_nao_relevantes)+len(tabela_nao_repetidas)))\n",
    "            else:\n",
    "                probFraseDadoN = probFraseDadoN * (1/(len(tabela_tweets_nao_relevantes)+len(tabela_nao_repetidas)))\n",
    "        listaN.append(probFraseDadoN)\n",
    "        i += 1\n",
    "\n",
    "    i = 0\n",
    "    listar = []\n",
    "    while i < 200:        \n",
    "        probRDadoFrase = listaR[i] * probR\n",
    "        listar.append(probRDadoFrase)\n",
    "        i += 1\n",
    "\n",
    "    i = 0\n",
    "    listan = []\n",
    "    while i < 200:\n",
    "        probNDadoFrase = listaN[i] * probN\n",
    "        listan.append(probNDadoFrase)\n",
    "        i += 1\n",
    "\n",
    "    i = 0\n",
    "    relevancia = []\n",
    "    while i < 200:        \n",
    "        if listar[i] > listan[i]:\n",
    "            relevancia.append(1)\n",
    "        else:\n",
    "            relevancia.append(0)\n",
    "        i += 1\n",
    "    return relevancia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Novamente transformando o excel Treinamento em uma lista de strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = pd.read_excel(filename)\n",
    "train2 = train1.Treinamento.apply(str)\n",
    "train3 = train2.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando a função (de relevância) criada na lista de strings (x1), retornando uma lista com as classificações obtidas. Fazendo uma lista com as classificações atribuídas pelos integrantes do grupo (vreal1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = relevante(train3)\n",
    "v1 = pd.Series(x1)\n",
    "vreal1 = train1.Relevância.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fazendo uma comparação para classificar e, posteriormente, extrair as contagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0      verdadeiro positivo\n1      verdadeiro negativo\n2      verdadeiro positivo\n3      verdadeiro negativo\n4      verdadeiro negativo\n              ...         \n195    verdadeiro positivo\n196    verdadeiro positivo\n197    verdadeiro positivo\n198    verdadeiro negativo\n199    verdadeiro negativo\nLength: 200, dtype: object"
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_porcentagens1 = [0] * len(x1)\r\n",
    "i = 0\r\n",
    "while i < len(x1):\r\n",
    "    if x1[i] == vreal1[i] and x1[i] == 0:\r\n",
    "        lista_porcentagens1[i] = 'verdadeiro negativo'\r\n",
    "    if x1[i] == vreal1[i] and x1[i] == 1:\r\n",
    "        lista_porcentagens1[i] = 'verdadeiro positivo'\r\n",
    "    if x1[i] != vreal1[i] and x1[i] == 0:\r\n",
    "        lista_porcentagens1[i] = 'falso negativo'\r\n",
    "    if x1[i] != vreal1[i] and x1[i] == 1:\r\n",
    "        lista_porcentagens1[i] = 'falso positivo'\r\n",
    "    i += 1\r\n",
    "\r\n",
    "porcentagens1 = pd.Series(lista_porcentagens1)\r\n",
    "porcentagens1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraindo as contagens obtidas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "verdadeiro positivo    59.0\nverdadeiro negativo    37.0\nfalso positivo          4.0\ndtype: float64"
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porcentagens1.value_counts(True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mensagens corretamente classificadas: Acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'96 %'"
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acuracia1 = 59 + 37\r\n",
    "acuracia1 = str(acuracia1) + ' %'\r\n",
    "acuracia1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformando o excel Teste em uma lista de strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = test.Teste.apply(str)\r\n",
    "test2 = test1.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando a função (de relevância) criada na lista de strings (x), retornando uma lista com as classificações obtidas. Fazendo uma lista com as classificações atribuídas pelos integrantes do grupo (vreal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = relevante(test2)\r\n",
    "v = pd.Series(x)\r\n",
    "vreal = test.Relevância.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fazendo uma comparação para classificar e, posteriormente, extrair as contagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0      verdadeiro negativo\n1           falso positivo\n2      verdadeiro positivo\n3      verdadeiro positivo\n4           falso positivo\n              ...         \n195    verdadeiro positivo\n196    verdadeiro positivo\n197         falso positivo\n198         falso positivo\n199         falso positivo\nLength: 200, dtype: object"
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_porcentagens = [0] * len(x)\r\n",
    "i = 0\r\n",
    "while i < len(x):\r\n",
    "    if x[i] == vreal[i] and x[i] == 0:\r\n",
    "        lista_porcentagens[i] = 'verdadeiro negativo'\r\n",
    "    if x[i] == vreal[i] and x[i] == 1:\r\n",
    "        lista_porcentagens[i] = 'verdadeiro positivo'\r\n",
    "    if x[i] != vreal[i] and x[i] == 0:\r\n",
    "        lista_porcentagens[i] = 'falso negativo'\r\n",
    "    if x[i] != vreal[i] and x[i] == 1:\r\n",
    "        lista_porcentagens[i] = 'falso positivo'\r\n",
    "    i += 1\r\n",
    "\r\n",
    "porcentagens = pd.Series(lista_porcentagens)\r\n",
    "porcentagens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraindo as seguintes contagens:\n",
    "\n",
    "- Porcentagem de verdadeiros positivos\n",
    "- Porcentagem de falsos positivos\n",
    "- Porcentagem de verdadeiros negativos\n",
    "- Porcentagem de falsos negativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "verdadeiro positivo    48.5\nfalso positivo         31.0\nverdadeiro negativo    15.0\nfalso negativo          5.5\ndtype: float64"
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porcentagens.value_counts(True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mensagens corretamente classificadas: Acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'63.5 %'"
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acuracia = 48.5 + 15.0\r\n",
    "acuracia = str(acuracia) + ' %'\r\n",
    "acuracia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\r\n",
    "## Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após o classificador ser utilizado, pode-se ver que ele obteve uma performance mediana, com uma acurácia de 63.5 % quando utilizado na planilha do excel de teste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com esses dados, pode-se entender que essa plataforma de classificação tem um índice de acertos satisfatório. Tendo em vista que a fonte de dados analisada pelo classificador pode ter, e nesse caso tem, novas palavras que não foram inseridas no treinamento dele, uma acurácia de mais da metade de seus itens reflete que a estratégia utilizada pelo grupo atendeu às expectativas propostas nesse projeto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porém, o grupo também entende que novas melhorias seriam necessárias para uma utilização realmente prática do nosso produto. Como por exemplo, um meio de adicionar à base de dados novas palavras e seus sentidos para relacioná-los à base de dados já existente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em relação à como nosso classificador Naive-Baiss analisa mensagens com duplo sentido, dupla negação ou sarcasmo, ele não tem uma ferramenta voltada para esse sentido, sendo esse um dos motivos para uma acurácia menor do que a esperada (um nível mais que satisfatório seria acima de 75% de acurácia)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparando o Treinamento e o Teste:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na análise do Treinamento, foram obtidos os seguintes resultados:\n",
    "\n",
    "- verdadeiro positivo: 59.0 %\n",
    "- verdadeiro negativo: 37.0 %\n",
    "- falso positivo: 4.0 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na análise do Teste, foram obtidos os seguintes resultados:\n",
    "\n",
    "- verdadeiro positivo: 48.5 %\n",
    "- falso positivo: 31.0 %\n",
    "- verdadeiro negativo: 15.0 %\n",
    "- falso negativo: 5.5 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com esses dados pode-se inferir que:\n",
    "\n",
    "- em ambas as análises, foram poucas (ou nula) as mensagens classificadas como falsos negativos;\n",
    "- a porcentagem de mensagens falsos positivos aumentou surpreendemente;\n",
    "- as porcentagens das mensagens verdadeiros positivos e das mensagens verdadeiros negativos abaixou;\n",
    "\n",
    "Muitas dessas alterações no resultado podem ter sido resultado de mensagens com duplo sentido, dupla negação ou sarcasmo, uma vez que esse classificador não capta essas nuances da língua humana."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propondo um plano de expansão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a expansão do nosso projeto como um todo, várias propostas podem ser colocadas em prática, porém as mais viáveis são de analisar o sentido de cada palavra em uma espécie de plataforma de pesquisa e assim poder analisar novas palavras de forma que a acurácia não diminua.\r\n",
    "Isso tendo em vista que ainda não é utilizada tal proposta pois ao não se ter anteriormente uma análise humana de quais palavras estão em tweets relevantes, termos seriam colocados aleatoriamente, atrapalhando ainda mais a performance do classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CORRIGIU separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "* CRIOU categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adição de mais tweets na base, conforme enunciado. (OBRIGATÓRIO PARA TRIOS, sem contar como item avançado)\n",
    "* EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "51b9ad24d63439ac1595c0936db43b926a873ce9029c5f9bea069af26a7b72f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "cb912411e23237fadbf4a5d0e899a2744866961a2205d2742a20610e6052bb20"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}