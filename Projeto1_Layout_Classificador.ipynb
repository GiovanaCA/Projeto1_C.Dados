{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nome: Guilherme dos Santos Martins\n",
    "\n",
    "Nome: Giovana Cassoni Andrade"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%matplotlib inline\r\n",
    "# !pip install emoji\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "import emoji\r\n",
    "from emoji import UNICODE_EMOJI"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Mostrando o diretório"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "print('Esperamos trabalhar no diretório')\r\n",
    "print(os.getcwd())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "c:\\Users\\guilh\\OneDrive\\Área de Trabalho\\Nova pasta (2)\\cd\\Projeto1_C.Dados-1\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "filename = 'Air Fryer.xlsx'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dados do Treinamento"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "train = pd.read_excel(filename)\r\n",
    "train.head(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevância</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air fryer pra canhoto</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@vanessapeitos @daizenbvc o franky conseguiria...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adoro poder aplicar meus conhecimentos de enge...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@leilodecornohu1 \"amigo estamos falando de buc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>se eu n mandar isso aqui na dm de alguma esqui...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relevância\n",
       "0                              air fryer pra canhoto           1\n",
       "1  @vanessapeitos @daizenbvc o franky conseguiria...           0\n",
       "2  adoro poder aplicar meus conhecimentos de enge...           1\n",
       "3  @leilodecornohu1 \"amigo estamos falando de buc...           0\n",
       "4  se eu n mandar isso aqui na dm de alguma esqui...           0"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tweets do treinamento"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "train.Treinamento"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0                                  air fryer pra canhoto\n",
       "1      @vanessapeitos @daizenbvc o franky conseguiria...\n",
       "2      adoro poder aplicar meus conhecimentos de enge...\n",
       "3      @leilodecornohu1 \"amigo estamos falando de buc...\n",
       "4      se eu n mandar isso aqui na dm de alguma esqui...\n",
       "                             ...                        \n",
       "295    @annaborgess air fryer eh foda simplesmente a ...\n",
       "296    e @chromavka que escolheria brócolis na air fr...\n",
       "297        estou morando em brasilia ou em uma air fryer\n",
       "298    queria agradecer ao ser humano que inventou a ...\n",
       "299    air fryer filha da puta, prega os trem tudo va...\n",
       "Name: Treinamento, Length: 300, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Probabilidades iniciais"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "probN = train.Relevância.value_counts(True)[0]\r\n",
    "probR = train.Relevância.value_counts(True)[1]\r\n",
    "probR, probN"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.58, 0.42)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dados do Teste"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\r\n",
    "test.head(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevância</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@poetatulio @tatyene_mendes isso é uma xota ou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comprei uma air fryer p minha mãe, o bagulho caro</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>usando air fryer como se não houvesse o amanhã</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>minha mãe comprou uma air fryer e já ama mais ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>repita comigo: churrasco na air fryer não existe!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Relevância\n",
       "0  @poetatulio @tatyene_mendes isso é uma xota ou...           0\n",
       "1  comprei uma air fryer p minha mãe, o bagulho caro           0\n",
       "2     usando air fryer como se não houvesse o amanhã           1\n",
       "3  minha mãe comprou uma air fryer e já ama mais ...           1\n",
       "4  repita comigo: churrasco na air fryer não existe!           0"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\r\n",
    "## Classificador automático de sentimento\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Faça aqui uma descrição do seu produto e o que considerou como relevante ou não relevante na classificação dos tweets.\r\n",
    "\r\n",
    "O produto analisado foi a Air Fryer, fritadeira que não utiliza de óleo e que é provinda de diversas marcas e podendo ter preços variados.\r\n",
    "Nossa classificação sobre a relevância de um tweet foi se ele falava bem ou mal do nosso produto analisado, sendo bem o relevante e mal um irrelevante."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Criando as funções de cleanup:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import re \r\n",
    "\r\n",
    "def cleanup(text):\r\n",
    "    punctuation = '[@!-.:?;()]'\r\n",
    "    pattern = re.compile(punctuation)\r\n",
    "    text_subbed = re.sub(pattern, '', text)\r\n",
    "    return text_subbed"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def cleanup2(text):\r\n",
    "    paragrafo = '\\n'\r\n",
    "    pattern = re.compile(paragrafo)\r\n",
    "    text_subbed = re.sub(pattern, ' ', text)\r\n",
    "    return text_subbed"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def cleanup3(text):\r\n",
    "    punctuation = '\\/'\r\n",
    "    pattern = re.compile(punctuation)\r\n",
    "    text_subbed = re.sub(pattern, ' ', text)\r\n",
    "    return text_subbed"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Separando os tweets pela classificação da relevância"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "trainR = train.loc[train['Relevância'] == 1,:]\r\n",
    "trainN = train.loc[train['Relevância'] == 0,:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Transformando os tweets relevantes em string e adicionando a uma lista"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "trainR = trainR.Treinamento.apply(str)\r\n",
    "trainR = trainR.to_list()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Transformando os tweets não relevantes em string e adicionando a uma lista"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "trainN = trainN.Treinamento.apply(str)\r\n",
    "trainN = trainN.to_list()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fazendo o cleanup em ambas as listas de tweets e o split"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "stringR = \" \"\r\n",
    "for i in trainR:\r\n",
    "    stringR = stringR + i + ' '\r\n",
    "stringR = stringR.lower()\r\n",
    "stringR = stringR.replace('air fryer', 'PRODUTO ')\r\n",
    "stringR = cleanup3(cleanup2(cleanup(stringR)))\r\n",
    "palavrasR = stringR.split()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "stringN = \" \"\r\n",
    "for i in trainN:\r\n",
    "    stringN = stringN + i + ' '\r\n",
    "stringN = stringN.lower()\r\n",
    "stringN = stringN.replace('air fryer', 'PRODUTO ')\r\n",
    "stringN = cleanup3(cleanup2(cleanup(stringN)))\r\n",
    "palavrasN = stringN.split()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Criando duas Series, uma com todas as palavras dos tweets relevantes e outra com todas as palavras dos tweets não relevantes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "serie_tweets_relevantes = pd.Series(palavrasR)\r\n",
    "# serie_tweets_relevantes.head(10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "serie_tweets_nao_relevantes = pd.Series(palavrasN)\r\n",
    "# serie_tweets_nao_relevantes.head(10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Contagem de cada uma das palavras de ambas as Series"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "tabela_tweets_relevantes = serie_tweets_relevantes.value_counts()\r\n",
    "# tabela_tweets_relevantes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "tabela_tweets_nao_relevantes = serie_tweets_nao_relevantes.value_counts()\r\n",
    "# tabela_tweets_nao_relevantes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Contagem dos valores relativos de ambas as Series"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "tabela_tweets_relevantes_relativa = serie_tweets_relevantes.value_counts(True)\r\n",
    "# tabela_tweets_relevantes_relativa"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "tabela_tweets_nao_relevantes_relativa = serie_tweets_nao_relevantes.value_counts(True)\r\n",
    "# tabela_tweets_nao_relevantes_relativa"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Transformando a tabela original Treinamento em string e lista para ter todos os tweets, não importando a classificação de relevância"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "train_str = train.Treinamento.apply(str)\r\n",
    "train = train_str.to_list()\r\n",
    "# train"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fazendo o cleanup e split de todos os tweets"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "string = \" \"\r\n",
    "for i in train:\r\n",
    "    string = string + i + ' '\r\n",
    "string = string.lower()\r\n",
    "string = string.replace('air fryer', 'PRODUTO ')\r\n",
    "string = cleanup3(cleanup2(cleanup(string)))\r\n",
    "palavras = string.split()\r\n",
    "# palavras"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Criando a Series com todas as palavras de todos os tweets"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "tabela_tweets = pd.Series(palavras)\r\n",
    "# tabela_tweets"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# tabela_tweets.to_frame()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "lista_dos_tweets = []\r\n",
    "lista_tweet = []\r\n",
    "for tweet in train:\r\n",
    "  lista_tweet.append(tweet)\r\n",
    "  lista_dos_tweets.append(lista_tweet)\r\n",
    "  lista_tweet = []\r\n",
    "# lista_dos_tweets\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "palavras_nao_repetidas = []\r\n",
    "for i in palavras:\r\n",
    "    if i not in palavras_nao_repetidas:\r\n",
    "        palavras_nao_repetidas.append(i)\r\n",
    "tabela_nao_repetidas = pd.Series(palavras_nao_repetidas)\r\n",
    "# tabela_nao_repetidas"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "i = 0\r\n",
    "y = []\r\n",
    "while i < 300:\r\n",
    "   x = lista_dos_tweets[i]\r\n",
    "   x = x[0].lower()\r\n",
    "   x = x.replace('air fryer', 'PRODUTO ')\r\n",
    "   x = cleanup3(cleanup2(cleanup(x)))\r\n",
    "   x=x.split()\r\n",
    "   y.append(x)\r\n",
    "   i+=1\r\n",
    "# y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "i = 0\r\n",
    "listaR = []\r\n",
    "while i < 300:\r\n",
    "    p = y[i]\r\n",
    "    probFraseDadoR = 1\r\n",
    "    for n in p:\r\n",
    "        if n in tabela_tweets_relevantes:\r\n",
    "            probFraseDadoR = probFraseDadoR * ((tabela_tweets_relevantes[n]+1)/(len(tabela_tweets_relevantes)+len(tabela_nao_repetidas)))\r\n",
    "        else:\r\n",
    "            probFraseDadoR = probFraseDadoR * (1/(len(tabela_tweets_relevantes)+len(tabela_nao_repetidas)))\r\n",
    "\r\n",
    "    listaR.append(probFraseDadoR)\r\n",
    "    i+=1\r\n",
    "# listaR"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "i = 0\r\n",
    "listaN = []\r\n",
    "while i < 300:\r\n",
    "    p = y[i]\r\n",
    "    probFraseDadoN = 1\r\n",
    "    for n in p:\r\n",
    "        if n in tabela_tweets_nao_relevantes:\r\n",
    "            probFraseDadoN = probFraseDadoN * ((tabela_tweets_nao_relevantes[n]+1)/(len(tabela_tweets_nao_relevantes)+len(tabela_nao_repetidas)))\r\n",
    "        else:\r\n",
    "            probFraseDadoN = probFraseDadoN * (1/(len(tabela_tweets_nao_relevantes)+len(tabela_nao_repetidas)))\r\n",
    "\r\n",
    "    listaN.append(probFraseDadoN)\r\n",
    "    i+=1\r\n",
    "# listaN"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "i = 0\r\n",
    "listar = []\r\n",
    "while i < 300:\r\n",
    "    probRDadoFrase = listaR[i] * probR\r\n",
    "    listar.append(probRDadoFrase)\r\n",
    "    i+=1\r\n",
    "# listar"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "i = 0\r\n",
    "listan = []\r\n",
    "while i < 300:\r\n",
    "    probNDadoFrase = listaN[i] * probN\r\n",
    "    listan.append(probNDadoFrase)\r\n",
    "    i+=1\r\n",
    "# listan"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "i = 0\r\n",
    "relevancia = []\r\n",
    "while i < 300:\r\n",
    "    if listar[i]>listan[i]:\r\n",
    "        relevancia.append(1)\r\n",
    "    else:\r\n",
    "        relevancia.append(0)\r\n",
    "    i+=1\r\n",
    "# relevancia\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "def relevante(lista_de_tweet):\r\n",
    "    lista_dos_tweets2 = []\r\n",
    "    lista_tweet2 = []\r\n",
    "    for tweet in lista_de_tweet:\r\n",
    "        lista_tweet2.append(tweet)\r\n",
    "        lista_dos_tweets2.append(lista_tweet2)\r\n",
    "        lista_tweet2 = []\r\n",
    "\r\n",
    "    i = 0\r\n",
    "    y1 = []\r\n",
    "    while i < 200:\r\n",
    "        x = lista_dos_tweets2[i]\r\n",
    "        x = x[0].lower()\r\n",
    "        x = x.replace('air fryer', 'PRODUTO ')\r\n",
    "        x = cleanup3(cleanup2(cleanup(x)))\r\n",
    "        x=x.split()\r\n",
    "        y1.append(x)\r\n",
    "        i+=1\r\n",
    "        \r\n",
    "    i = 0\r\n",
    "    listaR = []\r\n",
    "    while i < 200:        \r\n",
    "        p = y1[i]\r\n",
    "        probFraseDadoR = 1\r\n",
    "        for n in p:\r\n",
    "            if n in tabela_tweets_relevantes:\r\n",
    "                probFraseDadoR = probFraseDadoR * ((tabela_tweets_relevantes[n]+1)/(len(tabela_tweets_relevantes)+len(tabela_nao_repetidas)))\r\n",
    "            else:\r\n",
    "                probFraseDadoR = probFraseDadoR * (1/(len(tabela_tweets_relevantes)+len(tabela_nao_repetidas)))\r\n",
    "\r\n",
    "        listaR.append(probFraseDadoR)\r\n",
    "        i+=1\r\n",
    "\r\n",
    "    i = 0\r\n",
    "    listaN = []\r\n",
    "    while i < 200:       \r\n",
    "        p = y1[i]\r\n",
    "        probFraseDadoN = 1\r\n",
    "        for n in p:\r\n",
    "            if n in tabela_tweets_nao_relevantes:\r\n",
    "                probFraseDadoN = probFraseDadoN * ((tabela_tweets_nao_relevantes[n]+1)/(len(tabela_tweets_nao_relevantes)+len(tabela_nao_repetidas)))\r\n",
    "            else:\r\n",
    "                probFraseDadoN = probFraseDadoN * (1/(len(tabela_tweets_nao_relevantes)+len(tabela_nao_repetidas)))\r\n",
    "\r\n",
    "        listaN.append(probFraseDadoN)\r\n",
    "        i+=1\r\n",
    "\r\n",
    "    i = 0\r\n",
    "    listar = []\r\n",
    "    while i < 200:        \r\n",
    "        probRDadoFrase = listaR[i] * probR\r\n",
    "        listar.append(probRDadoFrase)\r\n",
    "        i+=1\r\n",
    "\r\n",
    "    i = 0\r\n",
    "    listan = []\r\n",
    "    while i < 200:\r\n",
    "        probNDadoFrase = listaN[i] * probN\r\n",
    "        listan.append(probNDadoFrase)\r\n",
    "        i+=1\r\n",
    "\r\n",
    "    i = 0\r\n",
    "    relevancia = []\r\n",
    "    while i < 200:        \r\n",
    "        if listar[i]>listan[i]:\r\n",
    "            relevancia.append(1)\r\n",
    "        else:\r\n",
    "            relevancia.append(0)\r\n",
    "        i+=1\r\n",
    "    return relevancia"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "train1 = pd.read_excel(filename)\r\n",
    "train2 = train1.Treinamento.apply(str)\r\n",
    "train3 = train2.to_list()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "x1 = relevante(train3)\r\n",
    "v1 = pd.Series(x1)\r\n",
    "vreal1 = train1.Relevância.to_list()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "lista_porcentagens1 = [0] * len(x1)\r\n",
    "i = 0\r\n",
    "while i < len(x1):\r\n",
    "    if x1[i] == vreal1[i] and x1[i] == 0:\r\n",
    "        lista_porcentagens1[i] = 'verdadeiro negativo'\r\n",
    "    if x1[i] == vreal1[i] and x1[i] == 1:\r\n",
    "        lista_porcentagens1[i] = 'verdadeiro positivo'\r\n",
    "    if x1[i] != vreal1[i] and x1[i] == 0:\r\n",
    "        lista_porcentagens1[i] = 'falso negativo'\r\n",
    "    if x1[i] != vreal1[i] and x1[i] == 1:\r\n",
    "        lista_porcentagens1[i] = 'falso positivo'\r\n",
    "    i += 1\r\n",
    "\r\n",
    "porcentagens1 = pd.Series(lista_porcentagens1)\r\n",
    "porcentagens1"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0      verdadeiro positivo\n",
       "1      verdadeiro negativo\n",
       "2      verdadeiro positivo\n",
       "3      verdadeiro negativo\n",
       "4      verdadeiro negativo\n",
       "              ...         \n",
       "195    verdadeiro positivo\n",
       "196    verdadeiro positivo\n",
       "197    verdadeiro positivo\n",
       "198    verdadeiro negativo\n",
       "199    verdadeiro negativo\n",
       "Length: 200, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "porcentagens1.value_counts(True) * 100"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "verdadeiro positivo    59.0\n",
       "verdadeiro negativo    37.0\n",
       "falso positivo          4.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "acuracia1 = 59 + 37\r\n",
    "acuracia1 = str(acuracia1) + ' %'\r\n",
    "acuracia1"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'96 %'"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "test1 = test.Teste.apply(str)\r\n",
    "test2 = test1.to_list()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "x = relevante(test2)\r\n",
    "v = pd.Series(x)\r\n",
    "vreal = test.Relevância.to_list()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "lista_porcentagens = [0] * len(x)\r\n",
    "i = 0\r\n",
    "while i < len(x):\r\n",
    "    if x[i] == vreal[i] and x[i] == 0:\r\n",
    "        lista_porcentagens[i] = 'verdadeiro negativo'\r\n",
    "    if x[i] == vreal[i] and x[i] == 1:\r\n",
    "        lista_porcentagens[i] = 'verdadeiro positivo'\r\n",
    "    if x[i] != vreal[i] and x[i] == 0:\r\n",
    "        lista_porcentagens[i] = 'falso negativo'\r\n",
    "    if x[i] != vreal[i] and x[i] == 1:\r\n",
    "        lista_porcentagens[i] = 'falso positivo'\r\n",
    "    i += 1\r\n",
    "\r\n",
    "porcentagens = pd.Series(lista_porcentagens)\r\n",
    "porcentagens"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0      verdadeiro negativo\n",
       "1           falso positivo\n",
       "2      verdadeiro positivo\n",
       "3      verdadeiro positivo\n",
       "4           falso positivo\n",
       "              ...         \n",
       "195    verdadeiro positivo\n",
       "196    verdadeiro positivo\n",
       "197         falso positivo\n",
       "198         falso positivo\n",
       "199         falso positivo\n",
       "Length: 200, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Extraindo as seguintes contagens:\n",
    "\n",
    "- Porcentagem de verdadeiros positivos\n",
    "- Porcentagem de falsos positivos\n",
    "- Porcentagem de verdadeiros negativos\n",
    "- Porcentagem de falsos negativos"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "porcentagens.value_counts(True) * 100"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "verdadeiro positivo    48.5\n",
       "falso positivo         31.0\n",
       "verdadeiro negativo    15.0\n",
       "falso negativo          5.5\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Mensagens corretamente classificadas: Acurácia"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "acuracia = 48.5 + 15.0\r\n",
    "acuracia = str(acuracia) + ' %'\r\n",
    "acuracia"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'63.5 %'"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\r\n",
    "## Concluindo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Após o classificador ser utilizado, pode-se ver que ele obteve uma performance mediana, com uma acurácia de 63.5 % quando utilizado na planilha do excel de teste."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Com esses dados, podemos entender que nossa plataforma de classificação tem um índice de acertos satisfatório. Tendo em vista que a fonte de dados analisada pelo classificador pode e tem novas palavras que não foram inseridas no treinamento dele, uma acurácia de mais da metade de seus itens reflete que a estratégia utilizada pelo grupo atendeu às expectativas propostas nesse projeto."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Porém o grupo também entende que novas melhorias seriam necessárias para uma utilização realmente prática do nosso produto. Como por exemplo um meio de adicionar à base de dados novas palavras e seus sentidos para relacioná-los à base de dados já existente."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Em relação à como nosso classificador Naive-Baiss analisa mensagens com duplo sentido, dupla negação ou sarcasmo, ele não tem uma ferramenta voltada para esse sentido, sendo esse um dos motivos para uma acurácia menor do que esperada (o mais que satisfatório seria acima de 75%)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Propondo um plano de expansão"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para a expansão do nosso projeto como um todo, várias propostas podem ser colocadas em prática, porém as mais viáveis são de analisar o sentido de cada palavra em uma espécie de plataforma de pesquisa e assim poder analisar novas palavras de forma que a acurácia não diminua."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CORRIGIU separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "* CRIOU categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adição de mais tweets na base, conforme enunciado. (OBRIGATÓRIO PARA TRIOS, sem contar como item avançado)\n",
    "* EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)"
   ],
   "metadata": {},
   "attachments": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## Referências"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "51b9ad24d63439ac1595c0936db43b926a873ce9029c5f9bea069af26a7b72f1"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "cb912411e23237fadbf4a5d0e899a2744866961a2205d2742a20610e6052bb20"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}